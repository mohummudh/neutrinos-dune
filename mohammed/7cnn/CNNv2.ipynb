{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ea91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks\n",
    "from uproot_io import Events, View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e40adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "events1 = Events(\"/Users/mohammed/code/neutrinos-dune-files/CheatedRecoFile_1.root\")\n",
    "events2 = Events(\"/Users/mohammed/code/neutrinos-dune-files/CheatedRecoFile_2.root\")\n",
    "events3 = Events(\"/Users/mohammed/code/neutrinos-dune-files/CheatedRecoFile_3.root\")\n",
    "events4 = Events(\"/Users/mohammed/code/neutrinos-dune-files/CheatedRecoFile_4.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0c5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers1 = np.array(list(set(events1.event_number)))\n",
    "numbers2 = np.array(list(set(events2.event_number)))\n",
    "numbers3 = np.array(list(set(events3.event_number)))\n",
    "numbers4 = np.array(list(set(events4.event_number)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44aab700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotLabelling():\n",
    "    label = []\n",
    "    \n",
    "    for n in numbers1:\n",
    "        mcp = []\n",
    "        index = np.where(events1.event_number == n)[0]\n",
    "\n",
    "        for i in index:\n",
    "            parent = events1.reco_parent_index[i]\n",
    "            if parent == 0:\n",
    "                mcp.append(events1.mc_pdg[i])\n",
    "\n",
    "        if 11 in mcp or -11 in mcp:\n",
    "            label.append([0,1,0])    \n",
    "        \n",
    "        elif 13 in mcp or -13 in mcp:\n",
    "            label.append([1,0,0])\n",
    "            \n",
    "        else:\n",
    "            label.append([0,0,1])\n",
    "            \n",
    "    for n in numbers2:\n",
    "        mcp = []\n",
    "        index = np.where(events2.event_number == n)[0]\n",
    "\n",
    "        for i in index:\n",
    "            parent = events2.reco_parent_index[i]\n",
    "            if parent == 0:\n",
    "                mcp.append(events2.mc_pdg[i])\n",
    "\n",
    "        if 11 in mcp or -11 in mcp:\n",
    "            label.append([0,1,0])    \n",
    "        \n",
    "        elif 13 in mcp or -13 in mcp:\n",
    "            label.append([1,0,0])\n",
    "            \n",
    "        else:\n",
    "            label.append([0,0,1])\n",
    "            \n",
    "    for n in numbers3:\n",
    "        mcp = []\n",
    "        index = np.where(events3.event_number == n)[0]\n",
    "\n",
    "        for i in index:\n",
    "            parent = events3.reco_parent_index[i]\n",
    "            if parent == 0:\n",
    "                mcp.append(events3.mc_pdg[i])\n",
    "\n",
    "        if 11 in mcp or -11 in mcp:\n",
    "            label.append([0,1,0])    \n",
    "        \n",
    "        elif 13 in mcp or -13 in mcp:\n",
    "            label.append([1,0,0])\n",
    "            \n",
    "        else:\n",
    "            label.append([0,0,1])\n",
    "            \n",
    "    for n in numbers4:\n",
    "        mcp = []\n",
    "        index = np.where(events4.event_number == n)[0]\n",
    "\n",
    "        for i in index:\n",
    "            parent = events4.reco_parent_index[i]\n",
    "            if parent == 0:\n",
    "                mcp.append(events4.mc_pdg[i])\n",
    "\n",
    "        if 11 in mcp or -11 in mcp:\n",
    "            label.append([0,1,0])    \n",
    "        \n",
    "        elif 13 in mcp or -13 in mcp:\n",
    "            label.append([1,0,0])\n",
    "            \n",
    "        else:\n",
    "            label.append([0,0,1])\n",
    "            \n",
    "    return np.array(label).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "000dc0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = oneHotLabelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f9cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('labels1',one_hot_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d5ece6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_w1 = View(events1, \"w\")\n",
    "view_w2 = View(events2, \"w\")\n",
    "view_w3 = View(events3, \"w\")\n",
    "view_w4 = View(events4, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb16b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagenew():\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for n in numbers1:\n",
    "    \n",
    "        x = view_w1.x[n]\n",
    "        z = view_w1.z[n]\n",
    "        adc = view_w1.adc[n]\n",
    "        vx = view_w1.true_vtx_x[n]\n",
    "        vz = view_w1.true_vtx_z[n]\n",
    "\n",
    "        matrix_size = 256\n",
    "        #if vz >\n",
    "\n",
    "        #range=[[np.floor(np.mean(x))-250, np.floor(np.mean(x))+250], [vz-250, vz+250]]\n",
    "\n",
    "        matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[np.floor(np.mean(x))-150, np.floor(np.mean(x))+150], [np.floor(np.mean(z))-150, np.floor(np.mean(z))+150]], weights=adc)\n",
    "        matrix = (matrix > 0).astype(int)\n",
    "\n",
    "        matrix = np.floor(matrix).astype(np.uint8).reshape(256, 256, 1)\n",
    "        images.append(matrix)\n",
    "        \n",
    "    for n in numbers2:\n",
    "    \n",
    "        x = view_w2.x[n]\n",
    "        z = view_w2.z[n]\n",
    "        adc = view_w2.adc[n]\n",
    "        vx = view_w2.true_vtx_x[n]\n",
    "        vz = view_w2.true_vtx_z[n]\n",
    "\n",
    "        matrix_size = 256\n",
    "        #if vz >\n",
    "\n",
    "        #range=[[np.floor(np.mean(x))-250, np.floor(np.mean(x))+250], [vz-250, vz+250]]\n",
    "\n",
    "        matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[np.floor(np.mean(x))-150, np.floor(np.mean(x))+150], [np.floor(np.mean(z))-150, np.floor(np.mean(z))+150]], weights=adc)\n",
    "        matrix = (matrix > 0).astype(int)\n",
    "\n",
    "        matrix = np.floor(matrix).astype(np.uint8).reshape(256, 256, 1)\n",
    "        images.append(matrix)\n",
    "        \n",
    "    for n in numbers3:\n",
    "    \n",
    "        x = view_w3.x[n]\n",
    "        z = view_w3.z[n]\n",
    "        adc = view_w3.adc[n]\n",
    "        vx = view_w3.true_vtx_x[n]\n",
    "        vz = view_w3.true_vtx_z[n]\n",
    "\n",
    "        matrix_size = 256\n",
    "        #if vz >\n",
    "\n",
    "        #range=[[np.floor(np.mean(x))-250, np.floor(np.mean(x))+250], [vz-250, vz+250]]\n",
    "\n",
    "        matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[np.floor(np.mean(x))-150, np.floor(np.mean(x))+150], [np.floor(np.mean(z))-150, np.floor(np.mean(z))+150]], weights=adc)\n",
    "        matrix = (matrix > 0).astype(int)\n",
    "\n",
    "        matrix = np.floor(matrix).astype(np.uint8).reshape(256, 256, 1)\n",
    "        images.append(matrix)\n",
    "        \n",
    "    for n in numbers4:\n",
    "    \n",
    "        x = view_w4.x[n]\n",
    "        z = view_w4.z[n]\n",
    "        adc = view_w4.adc[n]\n",
    "        vx = view_w4.true_vtx_x[n]\n",
    "        vz = view_w4.true_vtx_z[n]\n",
    "\n",
    "        matrix_size = 256\n",
    "        #if vz >\n",
    "\n",
    "        #range=[[np.floor(np.mean(x))-250, np.floor(np.mean(x))+250], [vz-250, vz+250]]\n",
    "\n",
    "        matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[np.floor(np.mean(x))-150, np.floor(np.mean(x))+150], [np.floor(np.mean(z))-150, np.floor(np.mean(z))+150]], weights=adc)\n",
    "        matrix = (matrix > 0).astype(int)\n",
    "\n",
    "        matrix = np.floor(matrix).astype(np.uint8).reshape(256, 256, 1)\n",
    "        images.append(matrix)\n",
    "\n",
    "\n",
    "    # Display the pixelated image\n",
    "    #plt.imshow(matrix.T, cmap='viridis', origin='lower', extent=[0, 128, 0, 128])\n",
    "    #plt.colorbar()\n",
    "    #plt.title('Pixelated Image of Energy')\n",
    "    #plt.show()\n",
    "    \n",
    "    return np.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "933ad557",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = imagenew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f919f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbersold = np.random.randint(0, len(one_hot_labels), len(one_hot_labels))\n",
    "seventy = int(0.7*len(random_numbersold))\n",
    "training = random_numbersold[:seventy]\n",
    "testing = random_numbersold[seventy:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c703581",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = images[training]\n",
    "y_train = one_hot_labels[training]\n",
    "\n",
    "x_test = images[testing]\n",
    "y_test = one_hot_labels[testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "badea35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39fbe7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "cnn_model = load_model('modelv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80779944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 10/204 [>.............................] - ETA: 9:20 - loss: 1.6439 - accuracy: 0.6961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0j/k5n00ph57w3c1tdfq0lwsgn00000gn/T/ipykernel_77866/2998528184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model using the training data with the true target outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Fill in the required arguments using the clues given above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m cnn_model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs,\n\u001b[0m\u001b[1;32m      4\u001b[0m               validation_data = (x_test, y_test), verbose = 1)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model using the training data with the true target outputs.\n",
    "# Fill in the required arguments using the clues given above\n",
    "cnn_model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs,\n",
    "              validation_data = (x_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b58ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size controls the number of images that are processed simultaneously\n",
    "batch_size = 128\n",
    "# The number of epochs that we want to train the network for\n",
    "epochs = 15\n",
    "# The learning rate (step size in gradient descent)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ffea417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function - for a multi-class classification task we need to\n",
    "# use categorical crossentropy loss\n",
    "loss_function = keras.losses.categorical_crossentropy\n",
    "# The optimiser performs the gradient descent for us. There are a few different\n",
    "# algorithms, but Adam is one of the more popular ones\n",
    "optimiser = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "# Now we compile the model with the loss function and optimiser\n",
    "cnn_model.compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc54f2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0j/k5n00ph57w3c1tdfq0lwsgn00000gn/T/ipykernel_13437/3679594676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Let's look at the whole test dataset, but you can reduce this to 1000 or so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# if you want run more quickly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mn_images_to_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Use the CNN to predict the classification of the images. It returns an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# containing the 10 class scores for each image. It is best to write this code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Make a list of incorrect classifications\n",
    "incorrect_indices = []\n",
    "# Let's look at the whole test dataset, but you can reduce this to 1000 or so\n",
    "# if you want run more quickly\n",
    "n_images_to_check = x_test.shape[0]\n",
    "# Use the CNN to predict the classification of the images. It returns an array\n",
    "# containing the 10 class scores for each image. It is best to write this code\n",
    "# using the array notation x[:i] that means use all values of x up until\n",
    "# the index i, such that if you changed the number of images above then it all\n",
    "# still works efficiently\n",
    "raw_predictions = cnn_model.predict(x = x_test[:n_images_to_check], batch_size = batch_size)\n",
    "for i in range(0,n_images_to_check):\n",
    "  # Remember the raw output from the CNN gives us an array of scores. We want\n",
    "  # to select the highest one as our prediction. We need to do the same thing\n",
    "  # for the truth too since we converted our numbers to a categorical\n",
    "  # representation earlier. We use the np.argmax() function for this\n",
    "  prediction = np.argmax(raw_predictions[i])\n",
    "  truth = np.argmax(y_test[i])\n",
    "  if prediction != truth:\n",
    "    incorrect_indices.append([i,prediction,truth])\n",
    "print('Number of images that were incorrectly classified =',len(incorrect_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "3350"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
