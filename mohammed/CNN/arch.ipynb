{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dabf21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from uproot_io import Events, View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d63403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "events = Events(\"/Users/mohammed/code/neutrinos-dune-files/CheatedRecoFile_1.root\")\n",
    "view_w = View(events, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b518ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_numbers = np.array(list(set(events.event_number)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13f8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotLabelling():\n",
    "    label = []\n",
    "    \n",
    "    for n in event_numbers:\n",
    "        mcp = []\n",
    "        index = np.where(events.event_number == n)[0]\n",
    "\n",
    "        for i in index:\n",
    "            parent = events.reco_parent_index[i]\n",
    "            if parent == 0:\n",
    "                mcp.append(events.mc_pdg[i])\n",
    "\n",
    "        if 11 in mcp or -11 in mcp:\n",
    "            label.append([0,1,0])    \n",
    "        \n",
    "        elif 13 in mcp or -13 in mcp:\n",
    "            label.append([1,0,0])\n",
    "            \n",
    "        else:\n",
    "            label.append([0,0,1])\n",
    "            \n",
    "    return np.array(label).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e551df",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = oneHotLabelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5bf106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image creation 2\n",
    "\n",
    "def imagenew():\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for n in event_numbers:\n",
    "    \n",
    "        x = view_w.x[n]\n",
    "        z = view_w.z[n]\n",
    "        adc = view_w.adc[n]\n",
    "        vx = view_w.true_vtx_x[n]\n",
    "        vz = view_w.true_vtx_z[n]\n",
    "\n",
    "        matrix_size = 256\n",
    "        #if vz >\n",
    "\n",
    "        #range=[[np.floor(np.mean(x))-250, np.floor(np.mean(x))+250], [vz-250, vz+250]]\n",
    "\n",
    "        matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[np.floor(np.mean(x))-150, np.floor(np.mean(x))+150], [np.floor(np.mean(z))-150, np.floor(np.mean(z))+150]], weights=adc)\n",
    "        matrix = (matrix > 0).astype(int)\n",
    "\n",
    "        matrix = np.floor(matrix).astype(np.uint8).reshape(256, 256, 1)\n",
    "        images.append(matrix)\n",
    "\n",
    "\n",
    "    # Display the pixelated image\n",
    "    #plt.imshow(matrix.T, cmap='viridis', origin='lower', extent=[0, 128, 0, 128])\n",
    "    #plt.colorbar()\n",
    "    #plt.title('Pixelated Image of Energy')\n",
    "    #plt.show()\n",
    "    \n",
    "    return np.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a4b4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = imagenew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232d30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbersold = np.random.randint(0, 1000, 1000)\n",
    "seventy = int(0.7*len(random_numbersold))\n",
    "training = random_numbersold[:seventy]\n",
    "testing = random_numbersold[seventy:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5da8a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = images[training]\n",
    "y_train = one_hot_labels[training]\n",
    "\n",
    "x_test = images[testing]\n",
    "y_test = one_hot_labels[testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60bc4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a2acd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "input_layer = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0f60320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size controls the number of images that are processed simultaneously\n",
    "batch_size = 256\n",
    "# The number of epochs that we want to train the network for - model 2, 20 is best\n",
    "epochs = 10\n",
    "# The learning rate (step size in gradient descent)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23dce2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function - for a multi-class classification task we need to\n",
    "# use categorical crossentropy loss\n",
    "loss_function = keras.losses.categorical_crossentropy\n",
    "# The optimiser performs the gradient descent for us. There are a few different\n",
    "# algorithms, but Adam is one of the more popular ones\n",
    "optimiser = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "# Now we compile the model with the loss function and optimiser\n",
    "model.compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c352b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/3 [=========>....................] - ETA: 1:11 - loss: 2.5980 - accuracy: 0.3359"
     ]
    }
   ],
   "source": [
    "# Train the model using the training data with the true target outputs.\n",
    "# Fill in the required arguments using the clues given above\n",
    "model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs,\n",
    "              validation_data = (x_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5dc02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
