{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07756831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import load_model\n",
    "from uproot_io import Events, View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "513f707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataSmall2/x_train.npy\")\n",
    "y_train = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataSmall2/y_train.npy\")\n",
    "\n",
    "x_val = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataSmall2/x_val.npy\")\n",
    "y_val = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataSmall2/y_val.npy\")\n",
    "\n",
    "x_test = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataSmall2/x_test.npy\")\n",
    "y_test = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataSmall2/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13968187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 63, 63, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 127008)            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 381027    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 381347 (1.45 MB)\n",
      "Trainable params: 381347 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Â model 1\n",
    "num_classes = 3\n",
    "input_layer = keras.layers.Input(x_train[0].shape)\n",
    "x = keras.layers.Conv2D(32, (3,3), activation='relu')(input_layer) \n",
    "x = keras.layers.MaxPooling2D((2,2))(x) \n",
    "x = keras.layers.Dropout(0.5)(x) \n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(num_classes, activation='softmax')(x) \n",
    "cnn_model1 = keras.Model(input_layer, x)\n",
    "cnn_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e48fe4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 7\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "512194be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = keras.losses.categorical_crossentropy\n",
    "optimiser = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "cnn_model1.compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c5e2c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "88/88 [==============================] - 23s 257ms/step - loss: 0.3201 - accuracy: 0.8759 - val_loss: 0.8931 - val_accuracy: 0.6979\n",
      "Epoch 2/7\n",
      "88/88 [==============================] - 22s 249ms/step - loss: 0.2880 - accuracy: 0.8907 - val_loss: 0.9277 - val_accuracy: 0.6928\n",
      "Epoch 3/7\n",
      "88/88 [==============================] - 22s 249ms/step - loss: 0.2716 - accuracy: 0.9000 - val_loss: 0.9541 - val_accuracy: 0.6949\n",
      "Epoch 4/7\n",
      "88/88 [==============================] - 24s 268ms/step - loss: 0.2575 - accuracy: 0.9026 - val_loss: 0.9966 - val_accuracy: 0.6858\n",
      "Epoch 5/7\n",
      "88/88 [==============================] - 26s 293ms/step - loss: 0.2464 - accuracy: 0.9053 - val_loss: 1.0292 - val_accuracy: 0.6901\n",
      "Epoch 6/7\n",
      "88/88 [==============================] - 24s 278ms/step - loss: 0.2362 - accuracy: 0.9100 - val_loss: 1.1009 - val_accuracy: 0.6874\n",
      "Epoch 7/7\n",
      "88/88 [==============================] - 22s 256ms/step - loss: 0.2309 - accuracy: 0.9121 - val_loss: 1.1219 - val_accuracy: 0.6855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29c385a60>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model1.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs,\n",
    "              validation_data = (x_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9162df89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 3s 37ms/step\n",
      "Number of images that were incorrectly classified = 3300\n"
     ]
    }
   ],
   "source": [
    "# Make a list of incorrect classifications\n",
    "incorrect_indices = []\n",
    "# Let's look at the whole test dataset, but you can reduce this to 1000 or so\n",
    "# if you want run more quickly\n",
    "n_images_to_check = x_test.shape[0]\n",
    "# Use the CNN to predict the classification of the images. It returns an array\n",
    "# containing the 10 class scores for each image. It is best to write this code\n",
    "# using the array notation x[:i] that means use all values of x up until\n",
    "# the index i, such that if you changed the number of images above then it all\n",
    "# still works efficiently\n",
    "raw_predictions = cnn_model1.predict(x = x_test[:n_images_to_check], batch_size = batch_size)\n",
    "for i in range(0,n_images_to_check):\n",
    "  # Remember the raw output from the CNN gives us an array of scores. We want\n",
    "  # to select the highest one as our prediction. We need to do the same thing\n",
    "  # for the truth too since we converted our numbers to a categorical\n",
    "  # representation earlier. We use the np.argmax() function for this\n",
    "  prediction = np.argmax(raw_predictions[i])\n",
    "  truth = np.argmax(y_test[i])\n",
    "  if prediction != truth:\n",
    "    incorrect_indices.append([i,prediction,truth])\n",
    "print('Number of images that were incorrectly classified =',len(incorrect_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05b8840c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7038499506416585"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (len(x_test)-3300)/len(x_test)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1461252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 6s 17ms/step - loss: 0.7611 - accuracy: 0.7038\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn_model1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c145e2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 128, 128, 1)       0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 128, 128, 64)      640       \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 128, 128, 64)      256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 128, 128, 64)      256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 64, 64, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 64, 64, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 64, 64, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 32, 32, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 32, 32, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 32, 32, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPooli  (None, 16, 16, 256)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               33554944  \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34706371 (132.39 MB)\n",
      "Trainable params: 34703555 (132.38 MB)\n",
      "Non-trainable params: 2816 (11.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, regularizers\n",
    "cnn_model2 = models.Sequential([\n",
    "        layers.Input(shape=x_train[0].shape),\n",
    "        layers.Rescaling(1./255),\n",
    "        \n",
    "        # First Conv Block with BatchNorm and MaxPooling\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Classifier\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "cnn_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de895b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 1000  # For example, 1000 samples\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Randomly select indices for the subset\n",
    "subset_indices = np.random.choice(x_train.shape[0], subset_size, replace=False)\n",
    "\n",
    "# Extract the subset of data and labels\n",
    "x_train_subset = x_train[subset_indices]\n",
    "y_train_subset = y_train[subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "39fb4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec816a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = keras.losses.categorical_crossentropy\n",
    "optimiser = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "cnn_model2.compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "349/349 [==============================] - 344s 984ms/step - loss: 0.8302 - accuracy: 0.6857 - val_loss: 1.7674 - val_accuracy: 0.4058\n",
      "Epoch 2/2\n",
      "285/349 [=======================>......] - ETA: 7:07 - loss: 0.6765 - accuracy: 0.7267"
     ]
    }
   ],
   "source": [
    "cnn_model2.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs,\n",
    "              validation_data = (x_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b52870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 40s 114ms/step - loss: 7.5386 - accuracy: 0.4141\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn_model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a679c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/Users/mohammed/code/neutrinos-dune-files/modelv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b713f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataBig/x_train.npy\")\n",
    "y_train = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataBig/y_train.npy\")\n",
    "\n",
    "x_val = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataBig/x_val.npy\")\n",
    "y_val = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataBig/y_val.npy\")\n",
    "\n",
    "x_test = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataBig/x_test.npy\")\n",
    "y_test = np.load(\"/Users/mohammed/code/neutrinos-dune-files/dataBig/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df111e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 22s 62ms/step - loss: 18.8156 - accuracy: 0.5949\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c3ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
