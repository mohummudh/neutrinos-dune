{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfea0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks\n",
    "from uproot_io import Events, View\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d74d01",
   "metadata": {},
   "source": [
    "# Building a CNN for event classification.\n",
    "\n",
    "We're only using **perfect reconstruction** (cheated files) for this.\n",
    "\n",
    "1. Need to obtain the truth record for each event, 0 for CC_mu, 1 for CC_e and 2 for NC_x. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b89ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "events = Events(\"/Users/mohammed/code/neutrinos-dune-files/CheatedRecoFile_1.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923ad3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2, ..., 9307, 9308, 9309], dtype=int32), 9310)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_numbers = np.array(list(set(events.event_number)))\n",
    "event_numbers, len(event_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e555e74",
   "metadata": {},
   "source": [
    "# Labelling the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a59ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling():\n",
    "    label = []\n",
    "#     bad = []\n",
    "    \n",
    "    for n in event_numbers:\n",
    "        mcp = []\n",
    "        index = np.where(events.event_number == n)[0]\n",
    "\n",
    "        for i in index:\n",
    "            parent = events.reco_parent_index[i]\n",
    "            if parent == 0:\n",
    "                mcp.append(events.mc_pdg[i])\n",
    "                \n",
    "#         if 13 in mcp and 11 in mcp:\n",
    "#             bad.append(n)\n",
    "#             label.append(3)\n",
    "        \n",
    "        if 13 in mcp or -13 in mcp:\n",
    "            label.append(0)\n",
    "\n",
    "        elif 11 in mcp or -11 in mcp:\n",
    "            label.append(1)    \n",
    "            \n",
    "        else:\n",
    "            label.append(2)\n",
    "            \n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85647b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c58538b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([3512.,    0.,    0.,    0.,    0., 3715.,    0.,    0.,    0.,\n",
       "         2083.]),\n",
       "  array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       "  <BarContainer object of 10 artists>),\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels), print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89a07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotLabelling():\n",
    "    label = []\n",
    "    \n",
    "    for n in event_numbers:\n",
    "        mcp = []\n",
    "        index = np.where(events.event_number == n)[0]\n",
    "\n",
    "        for i in index:\n",
    "            parent = events.reco_parent_index[i]\n",
    "            if parent == 0:\n",
    "                mcp.append(events.mc_pdg[i])\n",
    "\n",
    "        if 11 in mcp or -11 in mcp:\n",
    "            label.append([0,1,0])    \n",
    "        \n",
    "        elif 13 in mcp or -13 in mcp:\n",
    "            label.append([1,0,0])\n",
    "            \n",
    "        else:\n",
    "            label.append([0,0,1])\n",
    "            \n",
    "    return np.array(label).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea9c2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels = oneHotLabelling()\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c054a26",
   "metadata": {},
   "source": [
    "# Making the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57787178",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_w = View(events, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b3a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_w_event(number):\n",
    "    x = view_w.x[number]\n",
    "    z = view_w.z[number]\n",
    "    adc = view_w.adc[number]\n",
    "    vx = view_w.true_vtx_x[number]\n",
    "    vz = view_w.true_vtx_z[number]\n",
    "    \n",
    "    plt.scatter(x, z, c=adc, s=0.5)\n",
    "    plt.scatter(vx, vz, c='red', s=50)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('ADC')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('W Wire')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3630f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_w_event(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b09b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image creation 1\n",
    "\n",
    "def image():\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for n in event_numbers:\n",
    "    \n",
    "        x = view_w.x[n]\n",
    "        z = view_w.z[n]\n",
    "        adc = view_w.adc[n]\n",
    "\n",
    "        matrix_size = 128\n",
    "        matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[min(x), max(x)], [min(z), max(z)]], weights=adc)\n",
    "        matrix = np.floor(matrix).astype(np.uint8).reshape(128, 128, 1)\n",
    "        images.append(matrix)\n",
    "        \n",
    "#         matrix_size = 128\n",
    "#         hit_matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[min(x), max(x)], [min(z), max(z)]], weights=adc)\n",
    "#         hit_matrix = (hit_matrix > 0).astype(int)\n",
    "#         hit_matrix = np.floor(hit_matrix).astype(np.uint8).reshape(128, 128, 1)\n",
    "#         images.append(hit_matrix)\n",
    "        \n",
    "\n",
    "#         # Display the pixelated image\n",
    "#         plt.imshow(hit_matrix.T, cmap='viridis', origin='lower', extent=[0, 128, 0, 128])\n",
    "#         plt.colorbar()\n",
    "#         plt.title('Pixelated Image of Energy')\n",
    "#         plt.show()\n",
    "    \n",
    "    return np.stack(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a88dba",
   "metadata": {},
   "source": [
    "This improved version uses 256 pixels, and crops the picture by centering at the mean of x and z, and allowing 150 bins above and below this mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07825795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image creation 2\n",
    "\n",
    "def imagenew():\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for n in event_numbers:\n",
    "    \n",
    "        x = view_w.x[n]\n",
    "        z = view_w.z[n]\n",
    "        adc = view_w.adc[n]\n",
    "        vx = view_w.true_vtx_x[n]\n",
    "        vz = view_w.true_vtx_z[n]\n",
    "\n",
    "        matrix_size = 256\n",
    "        #if vz >\n",
    "\n",
    "        #range=[[np.floor(np.mean(x))-250, np.floor(np.mean(x))+250], [vz-250, vz+250]]\n",
    "\n",
    "        matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[np.floor(np.mean(x))-150, np.floor(np.mean(x))+150], [np.floor(np.mean(z))-150, np.floor(np.mean(z))+150]], weights=adc)\n",
    "        matrix = (matrix > 0).astype(int)\n",
    "\n",
    "        matrix = np.floor(matrix).astype(np.uint8).reshape(256, 256, 1)\n",
    "        images.append(matrix)\n",
    "\n",
    "\n",
    "    # Display the pixelated image\n",
    "    #plt.imshow(matrix.T, cmap='viridis', origin='lower', extent=[0, 128, 0, 128])\n",
    "    #plt.colorbar()\n",
    "    #plt.title('Pixelated Image of Energy')\n",
    "    #plt.show()\n",
    "    \n",
    "    return np.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593c37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = imagenew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65d113a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbersold = np.random.randint(0,max(event_numbers) , max(event_numbers))\n",
    "seventy = int(0.7*len(random_numbersold))\n",
    "training = random_numbersold[:seventy]\n",
    "testing = random_numbersold[seventy:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3699005",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.load(\"training_events.npy\")\n",
    "testing = np.load(\"testing_events.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed28d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = images[training]\n",
    "y_train = one_hot_labels[training]\n",
    "\n",
    "x_test = images[testing]\n",
    "y_test = one_hot_labels[testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dad88a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6445, 2763)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training), len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f4a7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa803e7",
   "metadata": {},
   "source": [
    "# The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01feed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 21:05:07.120087: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-01 21:05:07.120197: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-02-01 21:05:07.120405: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-02-01 21:05:07.120988: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-01 21:05:07.121439: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 127, 127, 32)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 516128)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 1548387   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1548707 (5.91 MB)\n",
      "Trainable params: 1548707 (5.91 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "\n",
    "input_layer = keras.layers.Input(x_train[0].shape)\n",
    "x = keras.layers.Conv2D(32, (3,3), activation='relu')(input_layer) # Replace None with a 2D convolution with 32 filters of size (3,3) and relu activation\n",
    "x = keras.layers.MaxPooling2D((2,2))(x) # Replace None with a MaxPooling2D layer to downsample by a factor of 2 in both dimensions\n",
    "x = keras.layers.Dropout(0.25)(x) # Replace None with a droput layer with a fraction of 0.25\n",
    "# x = keras.layers.Conv2D(32, (3,3), activation='relu')(x)\n",
    "# x = keras.layers.MaxPooling2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(num_classes, activation='softmax')(x) # Replace None with a final dense output layer with num_classes neurons and softmax activation\n",
    "cnn_model = keras.Model(input_layer, x)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edbb92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size controls the number of images that are processed simultaneously\n",
    "batch_size = 128\n",
    "# The number of epochs that we want to train the network for\n",
    "epochs = 15\n",
    "# The learning rate (step size in gradient descent)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96ff5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function - for a multi-class classification task we need to\n",
    "# use categorical crossentropy loss\n",
    "loss_function = keras.losses.categorical_crossentropy\n",
    "# The optimiser performs the gradient descent for us. There are a few different\n",
    "# algorithms, but Adam is one of the more popular ones\n",
    "optimiser = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "# Now we compile the model with the loss function and optimiser\n",
    "cnn_model.compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6895b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 21:05:08.243951: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 49s 959ms/step - loss: 0.8350 - accuracy: 0.6535 - val_loss: 0.6710 - val_accuracy: 0.7206\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0j/k5n00ph57w3c1tdfq0lwsgn00000gn/T/ipykernel_42963/2831852788.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model using the training data with the true target outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Fill in the required arguments using the clues given above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m cnn_model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs,\n\u001b[0m\u001b[1;32m      4\u001b[0m               validation_data = (x_test, y_test), verbose = 1)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model using the training data with the true target outputs.\n",
    "# Fill in the required arguments using the clues given above\n",
    "cnn_model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs,\n",
    "              validation_data = (x_test, y_test), verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model.save('modelv1')\n",
    "cnn_model = model.load('modelv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of incorrect classifications\n",
    "incorrect_indices = []\n",
    "# Let's look at the whole test dataset, but you can reduce this to 1000 or so\n",
    "# if you want run more quickly\n",
    "n_images_to_check = x_test.shape[0]\n",
    "# Use the CNN to predict the classification of the images. It returns an array\n",
    "# containing the 10 class scores for each image. It is best to write this code\n",
    "# using the array notation x[:i] that means use all values of x up until\n",
    "# the index i, such that if you changed the number of images above then it all\n",
    "# still works efficiently\n",
    "raw_predictions = cnn_model.predict(x = x_test[:n_images_to_check], batch_size = batch_size)\n",
    "for i in range(0,n_images_to_check):\n",
    "  # Remember the raw output from the CNN gives us an array of scores. We want\n",
    "  # to select the highest one as our prediction. We need to do the same thing\n",
    "  # for the truth too since we converted our numbers to a categorical\n",
    "  # representation earlier. We use the np.argmax() function for this\n",
    "  prediction = np.argmax(raw_predictions[i])\n",
    "  truth = np.argmax(y_test[i])\n",
    "  if prediction != truth:\n",
    "    incorrect_indices.append([i,prediction,truth])\n",
    "print('Number of images that were incorrectly classified =',len(incorrect_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (2761-473)/2761\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = x_train[0].shape  # Replace with the shape of your input data\n",
    "\n",
    "# Input layer\n",
    "input_layer = keras.layers.Input(x_train[0].shape)\n",
    "# Convolutional layers\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Flatten the output of the conv layers\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Dense layer\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)  # 3 classes for the output\n",
    "\n",
    "# Creating the model\n",
    "model = keras.Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48eca227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size controls the number of images that are processed simultaneously\n",
    "batch_size = 128\n",
    "# The number of epochs that we want to train the network for - model 2, 20 is best\n",
    "epochs = 15\n",
    "# The learning rate (step size in gradient descent)\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function - for a multi-class classification task we need to\n",
    "# use categorical crossentropy loss\n",
    "loss_function = keras.losses.categorical_crossentropy\n",
    "# The optimiser performs the gradient descent for us. There are a few different\n",
    "# algorithms, but Adam is one of the more popular ones\n",
    "optimiser = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "# Now we compile the model with the loss function and optimiser\n",
    "model.compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training data with the true target outputs.\n",
    "# Fill in the required arguments using the clues given above\n",
    "model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs,\n",
    "              validation_data = (x_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4f5d385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 13:47:15.148670: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-05 13:47:15.148916: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-02-05 13:47:15.148928: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-02-05 13:47:15.149498: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-05 13:47:15.149959: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# model.save('modelv2')\n",
    "model = load_model('/Users/mohammed/code/neutrinos-dune-files/modelv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b157f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 13:47:26.197653: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 6s 195ms/step\n",
      "Number of images that were incorrectly classified = 742\n"
     ]
    }
   ],
   "source": [
    "# Make a list of incorrect classifications\n",
    "incorrect_indices = []\n",
    "# Let's look at the whole test dataset, but you can reduce this to 1000 or so\n",
    "# if you want run more quickly\n",
    "n_images_to_check = x_test.shape[0]\n",
    "# Use the CNN to predict the classification of the images. It returns an array\n",
    "# containing the 10 class scores for each image. It is best to write this code\n",
    "# using the array notation x[:i] that means use all values of x up until\n",
    "# the index i, such that if you changed the number of images above then it all\n",
    "# still works efficiently\n",
    "raw_predictions = model.predict(x = x_test[:n_images_to_check], batch_size = batch_size)\n",
    "for i in range(0,n_images_to_check):\n",
    "  # Remember the raw output from the CNN gives us an array of scores. We want\n",
    "  # to select the highest one as our prediction. We need to do the same thing\n",
    "  # for the truth too since we converted our numbers to a categorical\n",
    "  # representation earlier. We use the np.argmax() function for this\n",
    "  prediction = np.argmax(raw_predictions[i])\n",
    "  truth = np.argmax(y_test[i])\n",
    "  if prediction != truth:\n",
    "    incorrect_indices.append([i,prediction,truth])\n",
    "print('Number of images that were incorrectly classified =',len(incorrect_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1637433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7312567910177472"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (2761-742)/2761\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e293230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can modify this part to draw different images from the failures list\n",
    "# You can change the value of im to look at different failures\n",
    "im = 3\n",
    "image_to_plot = x_test[incorrect_indices[im][0]]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "print('Incorrect classification for image',incorrect_indices[im][0],\n",
    "      ': predicted =',incorrect_indices[im][1],\n",
    "      'with true =',incorrect_indices[im][2])\n",
    "ax.imshow(image_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31239fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = []\n",
    "trut = []\n",
    "for i in range(0,n_images_to_check):\n",
    "    prediction = np.argmax(raw_predictions[i])\n",
    "    truth = np.argmax(y_test[i])\n",
    "    preds.append(prediction)\n",
    "    trut.append(truth)\n",
    "    \n",
    "conf_matrix = confusion_matrix(trut, preds)\n",
    "conf_matrix_decimals = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875946fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "heatmap = sns.heatmap(conf_matrix_decimals, annot=True, cmap='coolwarm', fmt=\".3f\", linewidths=.5, square=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e7952e",
   "metadata": {},
   "source": [
    "# Pandora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image():\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for n in event_numbers:\n",
    "\n",
    "        x = view_w.x[n]\n",
    "        z = view_w.z[n]\n",
    "        adc = view_w.adc[n]\n",
    "        \n",
    "        if len(x) > 0:\n",
    "            \n",
    "            matrix_size = 128\n",
    "            matrix, xedges, yedges = np.histogram2d(x, z, bins=matrix_size, range=[[min(x), max(x)], [min(z), max(z)]], weights=adc)\n",
    "\n",
    "            matrix = np.floor(matrix).astype(np.uint8).reshape(128, 128, 1)\n",
    "            images.append(matrix)\n",
    "        \n",
    "        else:\n",
    "            print(n)\n",
    "\n",
    "\n",
    "    #         # Display the pixelated image\n",
    "    #         plt.imshow(matrix.T, cmap='viridis', origin='lower', extent=[0, 128, 0, 128])\n",
    "    #         plt.colorbar()\n",
    "    #         plt.title('Pixelated Image of Energy')\n",
    "    #         plt.show()\n",
    "    \n",
    "    return np.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbersold = np.random.randint(0,9201 , 9201)\n",
    "seventy = int(0.7*len(random_numbersold))\n",
    "training = random_numbersold[:seventy]\n",
    "testing = random_numbersold[seventy:]\n",
    "# np.save(\"training_events\", training)\n",
    "# np.save(\"testing_events\", testing)\n",
    "\n",
    "\n",
    "# training = np.load(\"training_events.npy\")\n",
    "# testing = np.load(\"testing_events.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22331b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training)+len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a39dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefd0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = [2517, 2841, 5873, 6319, 7344, 7635, 7721, 8899]\n",
    "training = [x for x in training if x not in remove]\n",
    "testing = [x for x in testing if x not in remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = images[training]\n",
    "y_train = one_hot_labels[training]\n",
    "\n",
    "x_test = images[testing]\n",
    "y_test = one_hot_labels[testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotLabelling2():\n",
    "    label = []\n",
    "    \n",
    "    for n in event_numbers:\n",
    "        mcp = []\n",
    "        index = np.where(more.event_number == n)[0]\n",
    "\n",
    "        for i in index:\n",
    "            parent = more.reco_parent_index[i]\n",
    "            if parent == 0:\n",
    "                mcp.append(more.mc_pdg[i])\n",
    "\n",
    "        if 11 in mcp or -11 in mcp:\n",
    "            label.append([0,1,0])    \n",
    "        \n",
    "        elif 13 in mcp or -13 in mcp:\n",
    "            label.append([1,0,0])\n",
    "            \n",
    "        else:\n",
    "            label.append([0,0,1])\n",
    "            \n",
    "    return np.array(label).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = oneHotLabelling2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of incorrect classifications\n",
    "incorrect_indices = []\n",
    "# Let's look at the whole test dataset, but you can reduce this to 1000 or so\n",
    "# if you want run more quickly\n",
    "n_images_to_check = moreData.shape[0]\n",
    "# Use the CNN to predict the classification of the images. It returns an array\n",
    "# containing the 10 class scores for each image. It is best to write this code\n",
    "# using the array notation x[:i] that means use all values of x up until\n",
    "# the index i, such that if you changed the number of images above then it all\n",
    "# still works efficiently\n",
    "raw_predictions = cnn_model.predict(x = moreData[:n_images_to_check], batch_size = batch_size)\n",
    "for i in range(0,n_images_to_check):\n",
    "  # Remember the raw output from the CNN gives us an array of scores. We want\n",
    "  # to select the highest one as our prediction. We need to do the same thing\n",
    "  # for the truth too since we converted our numbers to a categorical\n",
    "  # representation earlier. We use the np.argmax() function for this\n",
    "  prediction = np.argmax(raw_predictions[i])\n",
    "  truth = np.argmax(y_test[i])\n",
    "  if prediction != truth:\n",
    "    incorrect_indices.append([i,prediction,truth])\n",
    "print('Number of images that were incorrectly classified =',len(incorrect_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "moreData.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c72e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (9265-2844)/9265\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8977c97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 32, 32, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16777344  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16870403 (64.36 MB)\n",
      "Trainable params: 16870403 (64.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model 2\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = x_train[0].shape  # Replace with the shape of your input data\n",
    "\n",
    "# Input layer\n",
    "input_layer = keras.layers.Input(x_train[0].shape)\n",
    "# Convolutional layers\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Flatten the output of the conv layers\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Dense layer\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)  # 3 classes for the output\n",
    "\n",
    "# Creating the model\n",
    "model = keras.Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7abed592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelv4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelv4/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('modelv4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627f32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
